{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üêò Automated Wildlife Tracking, Re-Identification & Analysis Pipeline\n",
        "\n",
        "This notebook implements an end-to-end pipeline for tracking wildlife (specifically trained on Elephants) in drone footage.\n",
        "\n",
        "**The Pipeline consists of four main steps:**\n",
        "1.  **Initial Tracking:** Uses **YOLOv11** with **BotSort** to detect and track animals frame-by-frame.\n",
        "2.  **Re-Identification (Post-Processing):** Analyzes \"broken\" tracks using **SIFT features** and **SSIM** to stitch trajectories of the same individual.\n",
        "3.  **Video Visualization:** Generates a final video overlaying the corrected IDs.\n",
        "4.  **Data Analysis:** Generates movement statistics, heatmaps, trajectory plots, and interaction (overlap/clustering) data."
      ],
      "metadata": {
        "id": "0FiCe_BdcfTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install Dependencies\n",
        "!pip install ultralytics opencv-python pandas scikit-image tqdm seaborn --quiet\n",
        "\n",
        "# 2. Imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "from ultralytics import YOLO\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# 3. Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- CONFIGURATION: UPDATE THIS PATH ---\n",
        "WORKING_DIR = ''\n",
        "INPUT_VIDEO = 'DJI_0395.MP4'       # Your video file name\n",
        "MODEL_WEIGHTS = 'best_xl.pt'       # Your trained YOLO model\n",
        "TRACKER_YAML = 'botsortV4.yaml'    # Your tracker config (optional)\n",
        "CONF_THRESHOLD = 0.50              # Confidence threshold\n",
        "OUTPUT_FOLDER = 'pipeline_results' # Where to save results\n",
        "\n",
        "# 4. Setup Environment\n",
        "if os.path.exists(WORKING_DIR):\n",
        "    os.chdir(WORKING_DIR)\n",
        "    print(f\"‚úÖ Working directory set to: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"‚ùå Error: Path not found: {WORKING_DIR}\")\n",
        "\n",
        "# Create output folders\n",
        "os.makedirs(os.path.join(OUTPUT_FOLDER, 'plots'), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_FOLDER, 'stats'), exist_ok=True)\n",
        "print(\"‚úÖ Environment Ready.\")"
      ],
      "metadata": {
        "id": "jd-uYuHUcfxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Initial Tracking (YOLO + BotSort)\n",
        "We use YOLOv11 to detect animals and BotSort to assign initial IDs. This data is saved as `tracking_raw.csv`."
      ],
      "metadata": {
        "id": "J8v35jUhc7OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_initial_tracking(video_path, model_path, tracker_config, output_csv):\n",
        "    print(f\"üöÄ Starting tracking on {video_path}...\")\n",
        "    model = YOLO(model_path)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    rows = []\n",
        "    tracker_arg = tracker_config if os.path.exists(tracker_config) else \"botsort.yaml\"\n",
        "\n",
        "    pbar = tqdm(total=total_frames, desc=\"Tracking\")\n",
        "    frame_num = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "        if not success: break\n",
        "\n",
        "        results = model.track(frame, persist=True, tracker=tracker_arg, conf=CONF_THRESHOLD, verbose=False)\n",
        "\n",
        "        if results[0].boxes.id is not None:\n",
        "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "            ids = results[0].boxes.id.cpu().numpy()\n",
        "            confs = results[0].boxes.conf.cpu().numpy()\n",
        "\n",
        "            for i, obj_id in enumerate(ids):\n",
        "                rows.append({\n",
        "                    'frame': frame_num,\n",
        "                    'id': int(obj_id),\n",
        "                    'xmin': float(boxes[i][0]),\n",
        "                    'ymin': float(boxes[i][1]),\n",
        "                    'xmax': float(boxes[i][2]),\n",
        "                    'ymax': float(boxes[i][3]),\n",
        "                    'confidence': float(confs[i])\n",
        "                })\n",
        "        frame_num += 1\n",
        "        pbar.update(1)\n",
        "    cap.release()\n",
        "    pbar.close()\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"‚úÖ Raw data saved to {output_csv}\")\n",
        "    return df\n",
        "\n",
        "# Run Step 1\n",
        "raw_csv_path = os.path.join(OUTPUT_FOLDER, 'tracking_raw.csv')\n",
        "if os.path.exists(INPUT_VIDEO):\n",
        "    df_raw = run_initial_tracking(INPUT_VIDEO, MODEL_WEIGHTS, TRACKER_YAML, raw_csv_path)\n",
        "else:\n",
        "    print(f\"‚ùå Video not found: {INPUT_VIDEO}\")"
      ],
      "metadata": {
        "id": "zUSJ7Wttc9kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Re-Identification (Re-ID)\n",
        "This step fixes \"broken\" tracks. It extracts frames where one ID ends and another begins, aligns them using **Homography**, and compares them using **SSIM**. If they match visually and physically (speed limit), the IDs are merged."
      ],
      "metadata": {
        "id": "NVDtHtqCc_m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Re-ID Helper Functions ---\n",
        "def extract_frame_img(video_path, frame_number):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
        "    success, frame = cap.read()\n",
        "    cap.release()\n",
        "    return frame if success else None\n",
        "\n",
        "def get_similarity_and_homography(img1, img2):\n",
        "    sift = cv2.SIFT_create()\n",
        "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
        "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
        "    if des1 is None or des2 is None: return 0.0, None\n",
        "\n",
        "    flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5), dict(checks=50))\n",
        "    matches = flann.knnMatch(des1, des2, k=2)\n",
        "    good = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
        "\n",
        "    if len(good) < 4: return 0.0, None\n",
        "    pts1 = np.float32([kp1[m.queryIdx].pt for m in good])\n",
        "    pts2 = np.float32([kp2[m.trainIdx].pt for m in good])\n",
        "\n",
        "    H, _ = cv2.findHomography(pts1, pts2, cv2.RANSAC)\n",
        "    if H is None: return 0.0, None\n",
        "\n",
        "    try:\n",
        "        h, w = img2.shape[:2]\n",
        "        warped = cv2.warpPerspective(img1, H, (w, h))\n",
        "        score, _ = ssim(cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY), cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY), full=True)\n",
        "        return score, H\n",
        "    except: return 0.0, None\n",
        "\n",
        "def transform_point(point, H):\n",
        "    p = np.dot(H, np.array([point[0], point[1], 1.0]).reshape((3, 1)))\n",
        "    return (p[:2] / p[2]).flatten() if p[2] != 0 else p[:2].flatten()\n",
        "\n",
        "def calculate_distance(p1, p2):\n",
        "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
        "\n",
        "def get_max_speed(df, obj_id):\n",
        "    t = df[df['id'] == obj_id].sort_values('frame')\n",
        "    if len(t) < 2: return 1000.0\n",
        "    speeds = [calculate_distance((t.iloc[i-1].xmin, t.iloc[i-1].ymin), (t.iloc[i].xmin, t.iloc[i].ymin)) * 30 for i in range(1, len(t))]\n",
        "    return max(speeds) if speeds else 0\n",
        "\n",
        "# --- Re-ID Execution ---\n",
        "def process_reid(df_raw, video_path, output_csv):\n",
        "    print(\"üß† Processing Re-ID...\")\n",
        "    # Filter low confidence\n",
        "    df_clean = df_raw[df_raw['id'].isin(df_raw.groupby('id')['confidence'].mean()[lambda x: x >= 0.5].index)].copy()\n",
        "\n",
        "    # Get candidates\n",
        "    lifespans = df_clean.groupby('id').agg(start=('frame', 'min'), end=('frame', 'max')).reset_index()\n",
        "    candidates = []\n",
        "    for a in lifespans.itertuples():\n",
        "        for b in lifespans.itertuples():\n",
        "            if a.id != b.id and b.start > a.end:\n",
        "                candidates.append((a.id, b.id, a.end, b.start))\n",
        "\n",
        "    # Cache frames\n",
        "    print(f\"Checking {len(candidates)} pairs...\")\n",
        "    frames = {f: extract_frame_img(video_path, f) for f in tqdm(set([c[2] for c in candidates] + [c[3] for c in candidates]))}\n",
        "\n",
        "    merges = []\n",
        "    for id_a, id_b, f_end, f_start in tqdm(candidates):\n",
        "        im_a, im_b = frames.get(f_end), frames.get(f_start)\n",
        "        if im_a is None or im_b is None: continue\n",
        "\n",
        "        score, H = get_similarity_and_homography(im_a, im_b)\n",
        "        if score > 0.50 and H is not None:\n",
        "            # Physics check\n",
        "            row_a, row_b = df_clean[(df_clean.id==id_a)&(df_clean.frame==f_end)].iloc[0], df_clean[(df_clean.id==id_b)&(df_clean.frame==f_start)].iloc[0]\n",
        "            center_a = [(row_a.xmin+row_a.xmax)/2, (row_a.ymin+row_a.ymax)/2]\n",
        "            center_b = [(row_b.xmin+row_b.xmax)/2, (row_b.ymin+row_b.ymax)/2]\n",
        "            dist = calculate_distance(transform_point(center_a, H), center_b)\n",
        "\n",
        "            if dist < (get_max_speed(df_clean, id_a) * (f_start - f_end)/30 * 1.5):\n",
        "                merges.append((id_a, id_b, score))\n",
        "\n",
        "    merges.sort(key=lambda x: x[2], reverse=True)\n",
        "    df_final = df_clean.copy()\n",
        "    processed = set()\n",
        "    count = 0\n",
        "    for old, new, _ in merges:\n",
        "        if new not in processed:\n",
        "            df_final.loc[df_final.id == new, 'id'] = old\n",
        "            processed.add(new)\n",
        "            count += 1\n",
        "\n",
        "    print(f\"üîó Merged {count} IDs.\")\n",
        "    df_final.to_csv(output_csv, index=False)\n",
        "    return df_final\n",
        "\n",
        "# Run Step 2\n",
        "reid_csv_path = os.path.join(OUTPUT_FOLDER, 'tracking_processed.csv')\n",
        "df_reid = process_reid(df_raw, INPUT_VIDEO, reid_csv_path)"
      ],
      "metadata": {
        "id": "zYlMDbnddBZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Video Visualization\n",
        "Generates `Final_Output_ReID.mp4` with the corrected IDs overlayed on the video."
      ],
      "metadata": {
        "id": "RDYrroTjdDci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_annotated_video(video_path, tracking_df, output_path):\n",
        "    print(f\"üé• Generating video: {output_path}\")\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    w, h = int(cap.get(3)), int(cap.get(4))\n",
        "    fps, total = int(cap.get(5)), int(cap.get(7))\n",
        "\n",
        "    writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "    purple = (128, 0, 128)\n",
        "\n",
        "    pbar = tqdm(total=total, desc=\"Rendering\")\n",
        "    frame_num = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "\n",
        "        for _, row in tracking_df[tracking_df.frame == frame_num].iterrows():\n",
        "            x1, y1, x2, y2 = int(row.xmin), int(row.ymin), int(row.xmax), int(row.ymax)\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), purple, 3)\n",
        "            cv2.putText(frame, f\"ID {int(row.id)} ({row.confidence:.2f})\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, purple, 2)\n",
        "\n",
        "        writer.write(frame)\n",
        "        frame_num += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    pbar.close()\n",
        "    print(\"‚ú® Video generation complete!\")\n",
        "\n",
        "final_vid_path = os.path.join(OUTPUT_FOLDER, 'Final_Output_ReID.mp4')\n",
        "create_annotated_video(INPUT_VIDEO, df_reid, final_vid_path)"
      ],
      "metadata": {
        "id": "D0fcV0kjdFZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Analysis & Statistics\n",
        "Calculates distances, overlaps, clusters, and density heatmaps.\n",
        "Results are saved in `pipeline_results/plots` and `pipeline_results/stats`."
      ],
      "metadata": {
        "id": "CuHJwPBXdHMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- STATISTICS FUNCTIONS ---\n",
        "\n",
        "def save_id_statistics(df, output_dir):\n",
        "    stats = df.groupby('id')['frame'].agg(['count'])\n",
        "    stats['seconds'] = stats['count'] / 30\n",
        "\n",
        "    avg_frames = stats['count'].mean()\n",
        "    avg_seconds = stats['seconds'].mean()\n",
        "\n",
        "    with open(os.path.join(output_dir, \"id_statistics.txt\"), \"w\") as f:\n",
        "        f.write(f\"Average number of frames each ID appears in: {avg_frames:.2f}\\n\")\n",
        "        f.write(f\"Average number of seconds each ID appears in: {avg_seconds:.2f}\\n\\n\")\n",
        "        f.write(\"Frame counts and seconds for each ID:\\n\")\n",
        "        f.write(\"ID | Frame Counts | Seconds\\n\")\n",
        "        f.write(\"-\" * 30 + \"\\n\")\n",
        "        for idx, row in stats.iterrows():\n",
        "            f.write(f\"{float(idx)} | {row['count']} | {row['seconds']:.2f}\\n\")\n",
        "\n",
        "def save_overlap_statistics(df, output_dir):\n",
        "    total_frames = df['frame'].nunique()\n",
        "    unique_overlaps = defaultdict(set)\n",
        "\n",
        "    for frame, group in df.groupby('frame'):\n",
        "        if len(group) < 2: continue\n",
        "        boxes = group[['id', 'xmin', 'ymin', 'xmax', 'ymax']].values\n",
        "        ids = boxes[:, 0]\n",
        "        x1, y1, x2, y2 = boxes[:, 1], boxes[:, 2], boxes[:, 3], boxes[:, 4]\n",
        "\n",
        "        for i in range(len(boxes)):\n",
        "            for j in range(i + 1, len(boxes)):\n",
        "                if (x1[i] < x2[j] and x2[i] > x1[j] and\n",
        "                    y1[i] < y2[j] and y2[i] > y1[j]):\n",
        "                    unique_overlaps[ids[i]].add(frame)\n",
        "                    unique_overlaps[ids[j]].add(frame)\n",
        "\n",
        "    res = []\n",
        "    for uid in df['id'].unique():\n",
        "        pct = (len(unique_overlaps[uid]) / total_frames) * 100\n",
        "        res.append({'id': float(uid), 'overlap_percentage': pct})\n",
        "\n",
        "    pd.DataFrame(res).sort_values('overlap_percentage', ascending=False)\\\n",
        "      .to_csv(os.path.join(output_dir, \"overlap.csv\"), sep='\\t', index=False)\n",
        "\n",
        "def find_connected_components(adj):\n",
        "    visited = set()\n",
        "    clusters = []\n",
        "    for node in adj:\n",
        "        if node not in visited:\n",
        "            component = []\n",
        "            stack = [node]\n",
        "            while stack:\n",
        "                n = stack.pop()\n",
        "                if n not in visited:\n",
        "                    visited.add(n)\n",
        "                    component.append(n)\n",
        "                    stack.extend(adj[n] - visited)\n",
        "            clusters.append(sorted(component))\n",
        "    return clusters\n",
        "\n",
        "def save_cluster_ranges(df, output_dir):\n",
        "    df['diagonal'] = np.sqrt((df.xmax - df.xmin)**2 + (df.ymax - df.ymin)**2)\n",
        "    history = []\n",
        "\n",
        "    for frame in sorted(df.frame.unique()):\n",
        "        curr = df[df.frame == frame]\n",
        "        if curr.empty: continue\n",
        "\n",
        "        thresh = curr['diagonal'].mean() * 1.5\n",
        "        adj = defaultdict(set)\n",
        "        for uid in curr.id.values: adj[uid] = set()\n",
        "\n",
        "        coords = curr[['x', 'y']].values\n",
        "        ids = curr.id.values\n",
        "\n",
        "        for i in range(len(ids)):\n",
        "            for j in range(i + 1, len(ids)):\n",
        "                if np.linalg.norm(coords[i] - coords[j]) < thresh:\n",
        "                    adj[ids[i]].add(ids[j])\n",
        "                    adj[ids[j]].add(ids[i])\n",
        "\n",
        "        clusters = find_connected_components(adj)\n",
        "        formatted = []\n",
        "        for c in clusters:\n",
        "            s = \"{\" + \" ,\".join([f\"{float(x)}\" for x in c]) + \" }\"\n",
        "            formatted.append(s)\n",
        "        formatted.sort()\n",
        "        history.append((frame, str(formatted)))\n",
        "\n",
        "    if not history: return\n",
        "    grouped = defaultdict(list)\n",
        "    last_state = history[0][1]\n",
        "    start = history[0][0]\n",
        "    end = start\n",
        "\n",
        "    for f, state in history[1:]:\n",
        "        if state == last_state and f == end + 1:\n",
        "            end = f\n",
        "        else:\n",
        "            grouped[last_state].append(f\"{start}-{end}\")\n",
        "            last_state = state\n",
        "            start = f\n",
        "            end = f\n",
        "    grouped[last_state].append(f\"{start}-{end}\")\n",
        "\n",
        "    rows = [{'Clusters': k, 'Frame Ranges': \", \".join(v)} for k, v in grouped.items()]\n",
        "    pd.DataFrame(rows).to_csv(os.path.join(output_dir, \"cluster_frame_ranges.csv\"), index=False)\n",
        "\n",
        "# --- PLOTTING FUNCTIONS ---\n",
        "\n",
        "def save_avg_distance_plot(df, output_dir):\n",
        "    daily = df.groupby('second')['distance'].mean()\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(daily.index, daily.values, label='Avg Distance')\n",
        "    plt.xlabel('Seconds'); plt.ylabel('Px / Frame')\n",
        "    plt.title('Average Movement Distance Over Time')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig(os.path.join(output_dir, \"avg_distance_plot.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def save_individual_distance_plots(df, output_dir):\n",
        "    \"\"\"Plots distance over time for EACH ID separately.\"\"\"\n",
        "    for uid in df.id.unique():\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sub = df[df.id == uid]\n",
        "        # Group by second to smooth out the plot slightly\n",
        "        grp = sub.groupby('second')['distance'].sum()\n",
        "        plt.plot(grp.index, grp.values)\n",
        "        plt.title(f'Distance Moved Per Second - ID {uid}')\n",
        "        plt.xlabel('Second'); plt.ylabel('Total Distance (px)')\n",
        "        plt.savefig(os.path.join(output_dir, f\"distance_plot_id_{uid}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "def save_trajectories_plot(df, output_dir):\n",
        "    \"\"\"Plots the X,Y path of every animal.\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for uid in df.id.unique():\n",
        "        sub = df[df.id == uid]\n",
        "        plt.plot(sub.x, sub.y, label=f'ID {uid}', alpha=0.7)\n",
        "        # Optional: Add start/end points\n",
        "        plt.scatter(sub.x.iloc[0], sub.y.iloc[0], marker='o', s=30)\n",
        "        plt.scatter(sub.x.iloc[-1], sub.y.iloc[-1], marker='x', s=30)\n",
        "\n",
        "    plt.title('Animal Trajectories')\n",
        "    plt.xlabel('X Position'); plt.ylabel('Y Position')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    # Invert Y axis because image coordinates start from top-left\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.savefig(os.path.join(output_dir, \"animal_trajectories.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def save_heatmap(df, output_dir):\n",
        "    \"\"\"Generates a density heatmap of animal positions.\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    try:\n",
        "        sns.kdeplot(x=df.x, y=df.y, cmap='viridis', fill=True, thresh=0.05, alpha=0.7)\n",
        "        plt.gca().invert_yaxis() # Match image coordinates\n",
        "        plt.title('Herd Density Heatmap')\n",
        "        plt.savefig(os.path.join(output_dir, \"density_heatmap.png\"))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not generate heatmap (not enough variance?): {e}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- MAIN CONTROLLER ---\n",
        "\n",
        "def run_analysis_final(df_in, output_folder):\n",
        "    print(\"üìä Starting Final Analysis...\")\n",
        "    stats_dir = os.path.join(output_folder, 'stats')\n",
        "    plots_dir = os.path.join(output_folder, 'plots')\n",
        "    os.makedirs(stats_dir, exist_ok=True)\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    # 1. Preprocessing\n",
        "    df = df_in.copy()\n",
        "    df['x'] = (df.xmin + df.xmax) / 2\n",
        "    df['y'] = (df.ymin + df.ymax) / 2\n",
        "    df['second'] = df.frame // 30\n",
        "\n",
        "    # 2. Distance Calculation\n",
        "    df = df.sort_values(['id', 'frame'])\n",
        "    prevs = df.groupby('id')[['x', 'y']].shift(1)\n",
        "    df['distance'] = np.sqrt((df.x - prevs.x)**2 + (df.y - prevs.y)**2).fillna(0)\n",
        "\n",
        "    # 3. Generate Stats Files\n",
        "    save_id_statistics(df, stats_dir)\n",
        "    save_overlap_statistics(df, stats_dir)\n",
        "    save_cluster_ranges(df, stats_dir)\n",
        "    df.groupby('id')['distance'].sum().reset_index().rename(columns={'id': 'id'})\\\n",
        "      .to_csv(os.path.join(stats_dir, \"sum_distance_per_id.csv\"), index=False)\n",
        "\n",
        "    # 4. Generate All Plots\n",
        "    print(\"   üé® Generating plots...\")\n",
        "    save_avg_distance_plot(df, plots_dir)\n",
        "    save_individual_distance_plots(df, plots_dir)\n",
        "    save_trajectories_plot(df, plots_dir)\n",
        "    save_heatmap(df, plots_dir)\n",
        "\n",
        "    print(f\"‚úÖ Analysis Complete. Files saved to: {output_folder}\")\n",
        "\n",
        "# Run Step 4\n",
        "if 'df_reid' in locals():\n",
        "    run_analysis_final(df_reid, OUTPUT_FOLDER)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Please run Step 2 first to generate 'df_reid'.\")"
      ],
      "metadata": {
        "id": "mAKFymSSk0Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NbZyPx9EpqxQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}