{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOa6RALY4iHymqdVyzLMlHj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# üìä YOLOv11 Model Evaluation Pipeline\n","\n","This notebook evaluates the performance of a trained YOLO model against a test dataset.\n","\n","**What this notebook does:**\n","1.  Loads your trained weights (`.pt` file).\n","2.  Runs validation on the test set defined in `TestData.yaml`.\n","3.  Calculates key metrics: **Precision, Recall, F1 Score, and mAP**.\n","4.  Visualizes the **Confusion Matrix** to show detection errors."],"metadata":{"id":"4lUUK1j1u_Z8"}},{"cell_type":"markdown","source":[],"metadata":{"id":"1okU5-MJvCFu"}},{"cell_type":"markdown","source":["## 1. Prerequisites & Dataset Structure\n","\n","Ensure your Google Drive is mounted and your files are organized.\n","\n","**1. Directory Structure:**\n","The evaluation script needs to find the `TestData.yaml` and the images it points to.\n","```text\n","/content/drive/MyDrive/datasets/\n","‚îÇ\n","‚îú‚îÄ‚îÄ TestData.yaml          <-- Config file\n","‚îú‚îÄ‚îÄ best_xl.pt             <-- Your trained model (move it here or update path)\n","‚îî‚îÄ‚îÄ test/                  <-- (Or 'val') Images to test against\n","    ‚îú‚îÄ‚îÄ images/\n","    ‚îî‚îÄ‚îÄ labels/"],"metadata":{"id":"QssTbmdxvCHs"}},{"cell_type":"code","source":["### **Cell 3: [Code] - Installation & Setup**\n","# @title 2. Install Dependencies & Mount Drive\n","%pip install ultralytics -q\n","\n","import torch\n","import os\n","import glob\n","from ultralytics import YOLO\n","from google.colab import drive\n","from IPython.display import Image, display\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Check GPU\n","print(f\"‚úÖ GPU Available: {torch.cuda.is_available()}\")"],"metadata":{"id":"tl5Q-xinu_y7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 3. Configuration\n","# --- USER INPUTS ---\n","# 1. Base Directory\n","WORKING_DIR = '/content/drive/MyDrive/datasets'\n","\n","# 2. Model Name/Path\n","# If you just finished training, the path might be inside 'runs/detect/...'\n","# Otherwise, copy your 'best.pt' to the WORKING_DIR and define it here.\n","MODEL_WEIGHTS = 'best_xl.pt'\n","\n","# 3. Dataset Config\n","DATA_YAML = 'TestData.yaml'\n","\n","# --- SETUP ---\n","if os.path.exists(WORKING_DIR):\n","    os.chdir(WORKING_DIR)\n","    print(f\"‚úÖ Working Directory set to: {os.getcwd()}\")\n","\n","    if not os.path.exists(MODEL_WEIGHTS):\n","        print(f\"‚ö†Ô∏è WARNING: Model file '{MODEL_WEIGHTS}' not found in current directory.\")\n","        print(\"   Please upload your .pt file or update the MODEL_WEIGHTS path.\")\n","    else:\n","        print(f\"‚úÖ Found model: {MODEL_WEIGHTS}\")\n","else:\n","    print(f\"‚ùå Error: Path not found: {WORKING_DIR}\")"],"metadata":{"id":"kRpbX7CwvOOS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Run Evaluation\n","\n","We will now run the `model.val()` command. This compares the model's predictions against the ground truth labels in your dataset.\n","\n","**Understanding the Metrics:**\n","* **Precision:** How accurate are the positive predictions? (Low precision = lots of False Positives/Hallucinations).\n","* **Recall:** How many actual objects did we find? (Low recall = lots of Missed Detections).\n","* **mAP50:** Mean Average Precision at 50% overlap. This is the standard \"grade\" for object detection models.\n","* **F1 Score:** A balanced score combining Precision and Recall."],"metadata":{"id":"OhFyLFm3vUVb"}},{"cell_type":"code","source":["# @title Run Validation & Calculate Metrics\n","if os.path.exists(MODEL_WEIGHTS):\n","    # 1. Load the model\n","    print(f\"üîÑ Loading model: {MODEL_WEIGHTS}...\")\n","    model = YOLO(MODEL_WEIGHTS)\n","\n","    # 2. Run Validation\n","    # We set split='test' to use the test set (if defined in YAML), otherwise it uses 'val'\n","    print(\"üöÄ Running validation (this may take a moment)...\")\n","    metrics = model.val(data=DATA_YAML, split='test', verbose=True)\n","\n","    # 3. Extract Metrics (Replicating logic from Eval.ipynb)\n","    # YOLOv11 stores results in the 'box' attribute\n","    map50 = metrics.box.map50\n","    map50_95 = metrics.box.map\n","    precision = metrics.box.mp  # Mean Precision\n","    recall = metrics.box.mr     # Mean Recall\n","\n","    # Calculate F1 Score manually\n","    # Formula: 2 * (P * R) / (P + R)\n","    if (precision + recall) > 0:\n","        f1_score = 2 * (precision * recall) / (precision + recall)\n","    else:\n","        f1_score = 0.0\n","\n","    # 4. Print Summary\n","    print(\"\\n\" + \"=\"*40)\n","    print(\"üèÜ FINAL EVALUATION REPORT\")\n","    print(\"=\"*40)\n","    print(f\"Precision:   {precision:.4f}\")\n","    print(f\"Recall:      {recall:.4f}\")\n","    print(f\"F1 Score:    {f1_score:.4f}\")\n","    print(f\"mAP @ 0.5:   {map50:.4f}\")\n","    print(f\"mAP @ 0.5:0.95: {map50_95:.4f}\")\n","    print(\"=\"*40)\n","\n","else:\n","    print(\"‚ùå Cannot run evaluation: Model file not found.\")"],"metadata":{"id":"lRgNfd_qvUuk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Visualizations\n","\n","YOLO automatically generates several plots to help analyze performance.\n","\n","* **Confusion Matrix:** Shows where the model is confused. (e.g., Is it mistaking an Elephant for the background?).\n","* **PR_curve:** Precision-Recall Curve.\n","* **F1_curve:** Shows how the F1 score changes with different confidence thresholds."],"metadata":{"id":"pl3wWU8uvYdc"}},{"cell_type":"code","source":["# @title Display Evaluation Plots\n","# Find the most recent validation folder created by YOLO\n","# usually runs/detect/val, val2, val3 etc.\n","output_dir = 'runs/detect'\n","if os.path.exists(output_dir):\n","    val_folders = sorted([f for f in os.listdir(output_dir) if 'val' in f],\n","                         key=lambda x: os.path.getmtime(os.path.join(output_dir, x)))\n","\n","    if val_folders:\n","        latest_val = os.path.join(output_dir, val_folders[-1])\n","        print(f\"üìÇ Displaying plots from: {latest_val}\")\n","\n","        # List of standard YOLO plot names\n","        plots = ['confusion_matrix.png', 'F1_curve.png', 'PR_curve.png', 'labels.jpg']\n","\n","        for plot_name in plots:\n","            path = os.path.join(latest_val, plot_name)\n","            if os.path.exists(path):\n","                print(f\"\\n--- {plot_name} ---\")\n","                display(Image(filename=path, width=600))\n","    else:\n","        print(\"‚ö†Ô∏è No validation folders found in runs/detect/\")\n","else:\n","    print(\"‚ö†Ô∏è 'runs/detect' folder not found.\")"],"metadata":{"id":"J1jkL2tnvYze"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 6. Test on a Single Random Image\n","# Run this to visually verify a detection on one image from your dataset\n","\n","import random\n","\n","# Get list of images\n","test_images_path = os.path.join(WORKING_DIR, 'test/images') # Update if your images are elsewhere\n","if not os.path.exists(test_images_path):\n","    test_images_path = os.path.join(WORKING_DIR, 'val/images')\n","\n","if os.path.exists(test_images_path):\n","    images = glob.glob(os.path.join(test_images_path, '*.jpg')) + glob.glob(os.path.join(test_images_path, '*.png'))\n","\n","    if images:\n","        # Pick random image\n","        random_img = random.choice(images)\n","        print(f\"üîé Detecting on: {os.path.basename(random_img)}\")\n","\n","        # Predict\n","        results = model.predict(random_img, conf=0.5)\n","\n","        # Show result\n","        for r in results:\n","            im_array = r.plot()  # plot a BGR numpy array of predictions\n","            im_rgb = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)\n","            display(Image(data=cv2.imencode('.jpg', im_array)[1].tobytes(), width=600))\n","    else:\n","        print(\"No images found to test.\")\n","else:\n","    print(f\"Image folder not found: {test_images_path}\")"],"metadata":{"id":"mh9HK1g8viIb"},"execution_count":null,"outputs":[]}]}